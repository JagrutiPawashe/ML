Linear Regression Steps:
1. Create the dataframe properly--> pd.read_csv(),pd.read_excel()
2. Preprocessing the data:
	a. Feature selection-->domain knowledge-->drop()
	b. Handling the missing values-->isnull().sum(),fillna(),dropna()
	c. Converting the categorical data to numerical-->map()
3. Assumption 1: There should be no outliers in the data-->boxplot()
4. Assumption 2: Assumption of Linearity:Every ind var should have a linear relationship 
with the dep var-->pairplot(), drop()
5. Create X and Y--> X= ind vars, Y=dep var
6. Assumption 3: Assumption of Normality: The dependent variable should follow an 
approximate normal distribtion-->distplot(),log()
7. Check and handle the skewness in the X vars-->hist(),skew(),log1p()
8. Assumption 4: Assumption of no multicollinearity: There should be no multicollinearity 
between the independent variables-->corr(),heatmap(),VIF(),drop()
9. Splitting the data into train and test(validation)-->train_test_split()
10. Building the model:
	a. Create the model-->obj=AlgoName()
	b. Train the model-->obj.fit(X_train,Y_train)
	c. Predict using the model-->Y_pred=obj.predict(X_test)
11. Evaluate the model:
	score, R-squared, Adj R-squared, RMSE, AIC/BIC 
12. Assumption 5: There should be no auto-correlation in the data-->Durbin Watson test
13. Assumption 6: Errors should be random-->Residual v/s Fitted plot
14. Assumption 7: Errors should follow an approx normal distribution-->Normal QQ plot
15. Assumption 8: Errors should follow a constant variance(Homoskedasticity)-->Scale-Location plot
16. Tuning the model:
	a. Feature selection-->domain knowledge, p-values
	b. Regularization techniques-->Ridge(),Lasso()
	c. Stochastic Gradient Descent
